{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Module 7: Logistic Regression"
      ],
      "metadata": {
        "id": "SvA9J1qYA7pG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0\n",
        "\n",
        "Load the appropriate libraries and bring in the data. Note that we have to run a script to get the [California Housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) to match as it is in scikit-learn. We cannot pull it directly from scikit-learn since CodeGrade cannot access the internet."
      ],
      "metadata": {
        "id": "ITR3BE6h7Rpe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFDJVenXA5Vb"
      },
      "outputs": [],
      "source": [
        "# CodeGrade step0\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.stats import pearsonr\n",
        "import os\n",
        "import tarfile\n",
        "import joblib # Imporxst joblib directly\n",
        "from sklearn.datasets._base import _pkl_filepath, get_data_home\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import seaborn as snsxs\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "archive_path = \"cal_housing.tgz\" # change the path if it's not in the current directory\n",
        "data_home = get_data_home(data_home=None) # change data_home if you are not using ~/scikit_learn_data\n",
        "if not os.path.exists(data_home):\n",
        "    os.makedirs(data_home)\n",
        "filepath = _pkl_filepath(data_home, 'cal_housing.pkz')\n",
        "\n",
        "with tarfile.open(mode=\"r:gz\", name=archive_path) as f:\n",
        "    cal_housing = np.loadtxt(\n",
        "        f.extractfile('CaliforniaHousing/cal_housing.data'),\n",
        "        delimiter=',')\n",
        "    # Columns are not in the same order compared to the previous\n",
        "    # URL resource on lib.stat.cmu.edu\n",
        "    columns_index = [8, 7, 2, 3, 4, 5, 6, 1, 0]\n",
        "    cal_housing = cal_housing[:, columns_index]\n",
        "\n",
        "    joblib.dump(cal_housing, filepath, compress=6) # Now using the directly imported joblib\n",
        "\n",
        "# Load dataset\n",
        "california = fetch_california_housing(as_frame=True)\n",
        "data = california.data\n",
        "data['MedianHouseValue'] = california.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the basic information of the data using `.info()` and `.describe`."
      ],
      "metadata": {
        "id": "dcyCF-RlD04q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display structure and summary\n"
      ],
      "metadata": {
        "id": "6Dj03YbpBfVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1\n",
        "\n",
        "Define `threshold` as the median of `MedianHouseValue`.\n",
        "\n",
        "Next create a binary target value called `HightValue` like so:\n",
        "\n",
        "> `data['HighValue'] = (data['MedianHouseValue'] > threshold).astype(int)`\n",
        "\n",
        "Finally give an array of the `unique_values` that returns the unique values of `HighValue`.\n"
      ],
      "metadata": {
        "id": "fVGLsOx37TbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step1\n"
      ],
      "metadata": {
        "id": "1cneP5e7Biji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2\n",
        "\n",
        "Select `MedInc`, `AveRoom`, and `AveOccup` as the variables of `X` and let `y` be the variable `HighValue`.\n",
        "\n",
        "Let `seed` be set to 42.\n",
        "\n",
        "Now split the data into `X_train`, `X_test`, `y_train`, and `y_test`, with a test stize of 30% and a random state of 42.\n",
        "\n",
        "Return the shapes of these four arrays in the same order as listed above."
      ],
      "metadata": {
        "id": "ocb1CXwp8Fy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step2\n"
      ],
      "metadata": {
        "id": "2Cu7i6YkCJR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3\n",
        "\n",
        "Using `scaler = StandardScaler()`, `fit_transform` `X_train`, calling this `X_train_scaled`. Likewise use `.transform` to transform `X_test` calling this `X_test_scaled`.\n",
        "\n",
        "Now return the shape of `X_test_scaled`."
      ],
      "metadata": {
        "id": "iMzZH3-o8qSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step3\n"
      ],
      "metadata": {
        "id": "TFc3ODXKChZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0\n",
        "\n",
        "Run the code below"
      ],
      "metadata": {
        "id": "uWO5q35P9mY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step0\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "hP-W8L6KCrOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4\n",
        "\n",
        "Return the model's intercept."
      ],
      "metadata": {
        "id": "xoF3knPa9o6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step4\n"
      ],
      "metadata": {
        "id": "bsHPL-EWCv5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5\n",
        "\n",
        "Return the model's coefficients."
      ],
      "metadata": {
        "id": "OaKQ8p9S-PvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step5\n"
      ],
      "metadata": {
        "id": "fYFMXdpiC5U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6\n",
        "\n",
        "Using the model, predict the probabilities of `X_test_scaled` calling this `y_pred_prob` and predict the class of `X_test_scaled` calling this `y_pred_class`.\n",
        "\n",
        "Now return the first five elments of both of these arrays, `y_pred_prob`, `y_pred_class`."
      ],
      "metadata": {
        "id": "4X8tgv6O-Vef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step6\n"
      ],
      "metadata": {
        "id": "SmUHBn7CC_Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7\n",
        "\n",
        "Give the confusion matrix of `y_test` and `y_pred_class`."
      ],
      "metadata": {
        "id": "iyLUKRFa-2uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # CodeGrade step7\n"
      ],
      "metadata": {
        "id": "sfZt6SYKDdje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8\n",
        "\n",
        "Roudning to four decimal places, give the accuracy score of `y_test` and `y_pred_class`."
      ],
      "metadata": {
        "id": "96SxReV9-9vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # CodeGrade step8\n"
      ],
      "metadata": {
        "id": "3aIwD_axDoNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9\n",
        "\n",
        "Rounding to 3 decimal placess for each, give the VIFs for each of the three columns of `X_trained_scaled`."
      ],
      "metadata": {
        "id": "j6-xxk_a_OLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # CodeGrade step9\n"
      ],
      "metadata": {
        "id": "403q_5eYD0Av"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}